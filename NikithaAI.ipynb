{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NikithaAI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyay10/Resources-for-SeSiGAN/blob/main/NikithaAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taf3cFPTzanv"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgWcWg14zbo-",
        "outputId": "5e3c6ddc-cd84-4217-8317-9531bfebd4a1"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnCmQzE-zdaU",
        "outputId": "c01b2cd3-f879-4fd3-9b45-6c969da867e8"
      },
      "source": [
        "!pip install imutils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gS_fu4JzftQ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "from os import listdir\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import imutils    \n",
        "\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle #shuffling the data improves the model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense,BatchNormalization, Flatten, MaxPool2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from keras.layers import Conv2D, Reshape\n",
        "from keras.backend import epsilon\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glnECsJdzuYU"
      },
      "source": [
        "image_dir=\"/content/drive/MyDrive/DATASETAI\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrVh5x260HbZ"
      },
      "source": [
        "os.makedirs('../output/kaggle/working/augmented-images')\n",
        "os.makedirs('../output/kaggle/working/augmented-images/yes')\n",
        "os.makedirs('../output/kaggle/working/augmented-images/no')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E4b31hd0MOE"
      },
      "source": [
        "def augment_data(file_dir, n_generated_samples, save_to_dir):\n",
        "    data_gen = ImageDataGenerator(rotation_range=10, \n",
        "                                  width_shift_range=0.1, \n",
        "                                  height_shift_range=0.1, \n",
        "                                  shear_range=0.1, \n",
        "                                  brightness_range=(0.3, 1.0),\n",
        "                                  horizontal_flip=True, \n",
        "                                  vertical_flip=True, \n",
        "                                  fill_mode='nearest'\n",
        "                                 )\n",
        "\n",
        "    for filename in listdir(file_dir):\n",
        "        image = cv2.imread(file_dir + '/' + filename)\n",
        "        # reshape the image\n",
        "        image = image.reshape((1,)+image.shape)\n",
        "        save_prefix = 'aug_' + filename[:-4]\n",
        "        i=0\n",
        "        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir,save_prefix=save_prefix, save_format='jpg'):\n",
        "          def augment_data(file_dir, n_generated_samples, save_to_dir):\n",
        "              data_gen = ImageDataGenerator(rotation_range=10, \n",
        "                                  width_shift_range=0.1, \n",
        "                                  height_shift_range=0.1, \n",
        "                                  shear_range=0.1, \n",
        "                                  brightness_range=(0.3, 1.0),\n",
        "                                  horizontal_flip=True, \n",
        "                                  vertical_flip=True, \n",
        "                                  fill_mode='nearest'\n",
        "                                 )\n",
        "\n",
        "    for filename in listdir(file_dir):\n",
        "        image = cv2.imread(file_dir + '/' + filename)\n",
        "        # reshape the image\n",
        "        image = image.reshape((1,)+image.shape)\n",
        "        save_prefix = 'aug_' + filename[:-4]\n",
        "        i=0\n",
        "        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir,save_prefix=save_prefix, save_format='jpg'):\n",
        "                i += 1\n",
        "                if i > n_generated_samples:\n",
        "                    break"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LambeB30a91"
      },
      "source": [
        "augmented_data_path ='../output/kaggle/working/augmented-images/'\n",
        "# augment data for the examples with label equal to 'no' representing non-tumurous examples\n",
        "augment_data(file_dir=image_dir+'/no', n_generated_samples=9, save_to_dir=augmented_data_path+'/no')\n",
        "# augment data for the examples with label equal to 'yes' representing tumurous examples\n",
        "augment_data(file_dir=image_dir+'/yes',n_generated_samples=6, save_to_dir=augmented_data_path+'/yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrAom1vm_ES2"
      },
      "source": [
        "def crop_brain_contour(image, plot=False):\n",
        "    \n",
        "    # Convert the image to grayscale, and blur it slightly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    \n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "    # Find contours in thresholded image, then grab the largest one\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "     c = max(cnts, key=cv2.contourArea)\n",
        "    # extreme points\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "    \n",
        "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
        "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
        "\n",
        "    if plot:\n",
        "        plt.figure()\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image)\n",
        "        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "        plt.title('Original Image')\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(new_image)\n",
        "        plt.tick_params(axis='both', which='both',top=False, bottom=False, left=False, right=False,labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "        plt.title('Cropped Image')\n",
        "        plt.show()\n",
        "    \n",
        "    return new_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2YGsJqZ_RkF"
      },
      "source": [
        "ex_img = cv2.imread(image_dir+'yes/Y107.jpg')\n",
        "ex_crop_img = crop_brain_contour(ex_img, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YTVQQo2_UFA"
      },
      "source": [
        "def load_data(dir_list, image_size):\n",
        "\n",
        "    # load all images in a directory\n",
        "    X = []\n",
        "    y = []\n",
        "    image_width, image_height = image_size\n",
        "    \n",
        "    for directory in dir_list:\n",
        "        for filename in listdir(directory):\n",
        "            image = cv2.imread(directory+'/'+filename)\n",
        "            image = crop_brain_contour(image, plot=False)\n",
        "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
        "            # normalize values\n",
        "            image = image / 255.\n",
        "            # convert image to numpy array and append it to X\n",
        "            X.append(image)\n",
        "            # append a value of 1 to the target array if the image\n",
        "             # is in the folder named 'yes', otherwise append 0.\n",
        "            if directory[-3:] == 'yes':\n",
        "                y.append([1])\n",
        "            else:\n",
        "                y.append([0])\n",
        "                \n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    \n",
        "    # Shuffle the data\n",
        "    X, y = shuffle(X, y)\n",
        "    \n",
        "    print(f'Number of examples is: {len(X)}')\n",
        "    print(f'X shape is: {X.shape}')\n",
        "    print(f'y shape is: {y.shape}')\n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ_gCuv0_cuj"
      },
      "source": [
        "augmented_yes =augmented_data_path+'yes'\n",
        "augmented_no = augmented_data_path+'no'\n",
        "\n",
        "IMG_WIDTH, IMG_HEIGHT = (224, 224)\n",
        "\n",
        "X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FO1F2sY_dz5"
      },
      "source": [
        "def plot_sample_images(X, y, n=40):\n",
        "    for label in [0,1]:\n",
        "        # grab the first n images with the corresponding y values equal to label\n",
        "        images = X[np.argwhere(y == label)]\n",
        "        n_images = images[:n]\n",
        "        \n",
        "        columns_n = 10\n",
        "        rows_n = int(n/ columns_n)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        \n",
        "        i = 1 # current plot        \n",
        "        for image in n_images:\n",
        "            plt.subplot(rows_n, columns_n, i)\n",
        "            plt.imshow(image[0])\n",
        "            \n",
        "            # remove ticks\n",
        "            plt.tick_params(axis='both', which='both', \n",
        "                            top=False, bottom=False, left=False, right=False,\n",
        "                           labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "            \n",
        "            i += 1\n",
        "        \n",
        "        label_to_str = lambda label: \"Yes\" if label == 1 else \"No\"\n",
        "        plt.suptitle(f\"Brain Tumor: {label_to_str(label)}\")\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pldBFyj_oSH"
      },
      "source": [
        "plot_sample_images(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9r2mvCp_qyR"
      },
      "source": [
        "def split_data(X, y, test_size=0.2):\n",
        "       \n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
        "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJeliqso_tK0"
      },
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whc5JyR5_u2a"
      },
      "source": [
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ocBBURS_w8u"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=7, input_shape=(224, 224, 3), activation='relu'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
        "model.add(MaxPooling2D(pool_size=4))\n",
        "model.add(MaxPooling2D(pool_size=4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF6C6n2P_zC4"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x=X_train, y=y_train, batch_size=32, epochs=22, validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Op3snW_1Vp"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOt9rEzW_4Do"
      },
      "source": [
        "# Loss Curves\n",
        "plt.figure(figsize=[14,10])\n",
        "plt.subplot(211)\n",
        "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)\n",
        " \n",
        "# Accuracy Curves\n",
        "plt.figure(figsize=[14,10])\n",
        "plt.subplot(212)\n",
        "plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}