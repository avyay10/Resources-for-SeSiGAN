{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# install an older version of tensorflow \n# (the implementation may not work with the most recent TensorFlow release)\n\n!pip install keras==2.3.1\n!pip install tensorflow==2.1.0","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:37:59.754179Z","iopub.execute_input":"2021-10-14T11:37:59.754614Z","iopub.status.idle":"2021-10-14T11:43:00.483771Z","shell.execute_reply.started":"2021-10-14T11:37:59.754579Z","shell.execute_reply":"2021-10-14T11:43:00.479989Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport glob\nimport os\n\nfrom keras import Input\nfrom keras.applications import VGG19\nfrom keras.callbacks import TensorBoard\nfrom keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\nfrom keras.layers import Conv2D, UpSampling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\n\nimport random\nfrom numpy import asarray\nfrom itertools import repeat\n\nimport imageio\nfrom imageio import imread\nfrom PIL import Image\nfrom skimage.transform import resize as imresize\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Tensorflow version \" + tf.__version__)\nprint(\"Keras version \" + tf.keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:43:00.488971Z","iopub.execute_input":"2021-10-14T11:43:00.489864Z","iopub.status.idle":"2021-10-14T11:43:08.695567Z","shell.execute_reply.started":"2021-10-14T11:43:00.489791Z","shell.execute_reply":"2021-10-14T11:43:08.694372Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# data path\nTRAIN_PATH = r'../input/kermany2018/OCT2017 /train/'\nVAL_PATH = r'../input/kermany2018/OCT2017 /val/'\nTEST_PATH = r'../input/kermany2018/OCT2017 /test/'\ndata_path = TRAIN_PATH\n\nepochs = 5001\n\n# batch size equals to 8 (due to RAM limits)\nbatch_size = 8\n\n# define the shape of low resolution image (LR) \nlow_resolution_shape = (64, 64, 3)\n\n# define the shape of high resolution image (HR) \nhigh_resolution_shape = (256, 256, 3)\n\n# optimizer for discriminator, generator \ncommon_optimizer = Adam(0.0002, 0.5)\n\n# use seed for reproducible results\nSEED = 2020 \ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:43:08.697582Z","iopub.execute_input":"2021-10-14T11:43:08.698092Z","iopub.status.idle":"2021-10-14T11:43:08.717738Z","shell.execute_reply.started":"2021-10-14T11:43:08.698040Z","shell.execute_reply":"2021-10-14T11:43:08.716250Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_train_images(data_path):\n\n    CLASSES = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n    image_list = []\n\n    for class_type in CLASSES:\n        image_list.extend(glob.glob(data_path + class_type + '/*'))\n    \n    return image_list    ","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:47:59.158402Z","iopub.execute_input":"2021-10-14T11:47:59.159405Z","iopub.status.idle":"2021-10-14T11:47:59.168162Z","shell.execute_reply.started":"2021-10-14T11:47:59.159350Z","shell.execute_reply":"2021-10-14T11:47:59.166693Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def find_img_dims(image_list):\n    \n    min_size = []\n    max_size = []\n    \n    for i in range(len(image_list)):\n        im = Image.open(image_list[i])\n        min_size.append(min(im.size))\n        max_size.append(max(im.size))\n    \n    return min(min_size), max(max_size)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:48:05.572039Z","iopub.execute_input":"2021-10-14T11:48:05.572509Z","iopub.status.idle":"2021-10-14T11:48:05.579601Z","shell.execute_reply.started":"2021-10-14T11:48:05.572476Z","shell.execute_reply":"2021-10-14T11:48:05.578607Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# get min/max image sizes\n\nimage_list = get_train_images(data_path)\nmin_size, max_size = find_img_dims(image_list)\nprint('The min and max image dims are {} and {} respectively.'\n      .format(min_size, max_size))","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:48:06.573405Z","iopub.execute_input":"2021-10-14T11:48:06.573878Z","iopub.status.idle":"2021-10-14T12:00:02.885239Z","shell.execute_reply.started":"2021-10-14T11:48:06.573834Z","shell.execute_reply":"2021-10-14T12:00:02.884142Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def compute_psnr(original_image, generated_image):\n    \n    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n    psnr = tf.image.psnr(original_image, generated_image, max_val=1.0)\n\n    return tf.math.reduce_mean(psnr, axis=None, keepdims=False, name=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:02.887789Z","iopub.execute_input":"2021-10-14T12:00:02.888143Z","iopub.status.idle":"2021-10-14T12:00:02.896634Z","shell.execute_reply.started":"2021-10-14T12:00:02.888109Z","shell.execute_reply":"2021-10-14T12:00:02.895178Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def plot_psnr(psnr):\n    \n    psnr_means = psnr['psnr_quality']\n    plt.figure(figsize=(10,8))\n    plt.plot(psnr_means)    \n    plt.xlabel('Epochs')\n    plt.ylabel('PSNR') \n    plt.title('PSNR')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:02.898347Z","iopub.execute_input":"2021-10-14T12:00:02.898665Z","iopub.status.idle":"2021-10-14T12:00:03.144245Z","shell.execute_reply.started":"2021-10-14T12:00:02.898635Z","shell.execute_reply":"2021-10-14T12:00:03.143242Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def compute_ssim(original_image, generated_image):\n    \n    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n    ssim = tf.image.ssim(original_image, generated_image, max_val=1.0, filter_size=11,\n                          filter_sigma=1.5, k1=0.01, k2=0.03)\n\n    return tf.math.reduce_mean(ssim, axis=None, keepdims=False, name=None)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.145790Z","iopub.execute_input":"2021-10-14T12:00:03.146137Z","iopub.status.idle":"2021-10-14T12:00:03.156249Z","shell.execute_reply.started":"2021-10-14T12:00:03.146104Z","shell.execute_reply":"2021-10-14T12:00:03.155152Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def plot_ssim(ssim):\n    \n    ssim_means = ssim['ssim_quality']\n\n    plt.figure(figsize=(10,8))\n    plt.plot(ssim_means)\n    plt.xlabel('Epochs')\n    plt.ylabel('SSIM')\n    plt.title('SSIM')","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.158954Z","iopub.execute_input":"2021-10-14T12:00:03.159326Z","iopub.status.idle":"2021-10-14T12:00:03.167241Z","shell.execute_reply.started":"2021-10-14T12:00:03.159289Z","shell.execute_reply":"2021-10-14T12:00:03.166334Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def plot_loss(losses):\n\n    d_loss = losses['d_history']\n    g_loss = losses['g_history']\n    \n   \n    plt.figure(figsize=(10,8))\n    plt.plot(d_loss, label=\"Discriminator loss\")\n    plt.plot(g_loss, label=\"Generator loss\")\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(\"Loss\")    \n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.168429Z","iopub.execute_input":"2021-10-14T12:00:03.168722Z","iopub.status.idle":"2021-10-14T12:00:03.179245Z","shell.execute_reply.started":"2021-10-14T12:00:03.168694Z","shell.execute_reply":"2021-10-14T12:00:03.178050Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def sample_images(image_list, batch_size, high_resolution_shape, low_resolution_shape):\n    \n    \"\"\"\n    Pre-process a batch of training images\n    \"\"\"\n    \n    # image_list is the list of all images\n    # ransom sample a batch of images\n    images_batch = np.random.choice(image_list, size=batch_size)\n    \n    lr_images = []\n    hr_images = []\n    \n\n    for img in images_batch:\n  \n        img1 = imread(img, as_gray=False, pilmode='RGB')\n        #img1 = imread(img, pilmode='RGB')\n        img1 = img1.astype(np.float32)\n        \n        # change the size     \n        img1_high_resolution = imresize(img1, high_resolution_shape)\n        img1_low_resolution = imresize(img1, low_resolution_shape)\n                \n\n        # do a random horizontal flip\n        if np.random.random() < 0.5:\n            img1_high_resolution = np.fliplr(img1_high_resolution)\n            img1_low_resolution = np.fliplr(img1_low_resolution)\n       \n        hr_images.append(img1_high_resolution)\n        lr_images.append(img1_low_resolution)\n        \n   \n    # convert lists into numpy ndarrays\n    return np.array(hr_images), np.array(lr_images)    ","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.180865Z","iopub.execute_input":"2021-10-14T12:00:03.181187Z","iopub.status.idle":"2021-10-14T12:00:03.192913Z","shell.execute_reply.started":"2021-10-14T12:00:03.181157Z","shell.execute_reply":"2021-10-14T12:00:03.191612Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def save_images(original_image, lr_image, sr_image, path):\n    \n    \"\"\"\n    Save LR, HR (original) and generated SR\n    images in one panel \n    \"\"\"\n    \n    fig, ax = plt.subplots(1,3, figsize=(10, 6))\n\n    images = [original_image, lr_image, sr_image]\n    titles = ['HR', 'LR','SR - generated']\n\n    for idx,img in enumerate(images):\n        # (X + 1)/2 to scale back from [-1,1] to [0,1]\n        ax[idx].imshow((img + 1)/2.0, cmap='gray')\n        ax[idx].axis(\"off\")\n    for idx, title in enumerate(titles):    \n        ax[idx].set_title('{}'.format(title))\n        \n    plt.savefig(path)    ","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.194490Z","iopub.execute_input":"2021-10-14T12:00:03.195104Z","iopub.status.idle":"2021-10-14T12:00:03.210868Z","shell.execute_reply.started":"2021-10-14T12:00:03.195063Z","shell.execute_reply":"2021-10-14T12:00:03.209908Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def residual_block(x):\n\n    filters = [64, 64]\n    kernel_size = 3\n    strides = 1\n    padding = \"same\"\n    momentum = 0.8\n    activation = \"relu\"\n\n    res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n    res = Activation(activation=activation)(res)\n    res = BatchNormalization(momentum=momentum)(res)\n\n    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n    res = BatchNormalization(momentum=momentum)(res)\n\n    res = Add()([res, x])\n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.212468Z","iopub.execute_input":"2021-10-14T12:00:03.213058Z","iopub.status.idle":"2021-10-14T12:00:03.225388Z","shell.execute_reply.started":"2021-10-14T12:00:03.213019Z","shell.execute_reply":"2021-10-14T12:00:03.224148Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def build_generator():\n    \n    # use 16 residual blocks in generator\n    residual_blocks = 16\n    momentum = 0.8\n    \n    # input LR dimension: 4x downsample of HR\n    input_shape = (64, 64, 3)\n    \n    # input for the generator\n    input_layer = Input(shape=input_shape)\n    \n    # pre-residual block: conv layer before residual blocks \n    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n    \n    # add 16 residual blocks\n    res = residual_block(gen1)\n    for i in range(residual_blocks - 1):\n        res = residual_block(res)\n    \n    # post-residual block: conv and batch-norm layer after residual blocks\n    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n    gen2 = BatchNormalization(momentum=momentum)(gen2)\n    \n    # take the sum of pre-residual block(gen1) and post-residual block(gen2)\n    gen3 = Add()([gen2, gen1])\n    \n    # upsampling\n    gen4 = UpSampling2D(size=2)(gen3)\n    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n    gen4 = Activation('relu')(gen4)\n    \n    # upsampling\n    gen5 = UpSampling2D(size=2)(gen4)\n    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n    gen5 = Activation('relu')(gen5)\n    \n    # conv layer at the output\n    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n    output = Activation('tanh')(gen6)\n    \n    # model \n    model = Model(inputs=[input_layer], outputs=[output], name='generator')\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:00:03.226968Z","iopub.execute_input":"2021-10-14T12:00:03.227329Z","iopub.status.idle":"2021-10-14T12:00:03.242270Z","shell.execute_reply.started":"2021-10-14T12:00:03.227291Z","shell.execute_reply":"2021-10-14T12:00:03.241382Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"generator = build_generator()","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:09:16.498948Z","iopub.execute_input":"2021-10-14T12:09:16.499454Z","iopub.status.idle":"2021-10-14T12:09:17.775520Z","shell.execute_reply.started":"2021-10-14T12:09:16.499416Z","shell.execute_reply":"2021-10-14T12:09:17.774048Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def build_discriminator():\n    \n    # define hyperparameters\n    leakyrelu_alpha = 0.2\n    momentum = 0.8\n    \n    # the input is the HR shape\n    input_shape = (256, 256, 3)\n    \n    # input layer for discriminator\n    input_layer = Input(shape=input_shape)\n    \n    # 8 convolutional layers with batch normalization  \n    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n\n    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n    dis2 = BatchNormalization(momentum=momentum)(dis2)\n\n    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n    dis3 = BatchNormalization(momentum=momentum)(dis3)\n\n    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n    dis4 = BatchNormalization(momentum=0.8)(dis4)\n\n    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n    dis5 = BatchNormalization(momentum=momentum)(dis5)\n\n    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n    dis6 = BatchNormalization(momentum=momentum)(dis6)\n\n    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n    dis7 = BatchNormalization(momentum=momentum)(dis7)\n\n    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n    dis8 = BatchNormalization(momentum=momentum)(dis8)\n    \n    # fully connected layer \n    dis9 = Dense(units=1024)(dis8)\n    dis9 = LeakyReLU(alpha=0.2)(dis9)\n    \n    # last fully connected layer - for classification \n    output = Dense(units=1, activation='sigmoid')(dis9)   \n    \n    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:09:17.780511Z","iopub.execute_input":"2021-10-14T12:09:17.780862Z","iopub.status.idle":"2021-10-14T12:09:17.802504Z","shell.execute_reply.started":"2021-10-14T12:09:17.780829Z","shell.execute_reply":"2021-10-14T12:09:17.801590Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"discriminator = build_discriminator()\ndiscriminator.trainable = True\ndiscriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:09:19.426706Z","iopub.execute_input":"2021-10-14T12:09:19.427123Z","iopub.status.idle":"2021-10-14T12:09:19.794953Z","shell.execute_reply.started":"2021-10-14T12:09:19.427090Z","shell.execute_reply":"2021-10-14T12:09:19.793704Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"VGG19_base = VGG19(weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:09:22.071175Z","iopub.execute_input":"2021-10-14T12:09:22.071666Z","iopub.status.idle":"2021-10-14T12:09:44.486322Z","shell.execute_reply.started":"2021-10-14T12:09:22.071629Z","shell.execute_reply":"2021-10-14T12:09:44.483523Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def build_VGG19():\n    \n    input_shape = (256, 256, 3)\n    VGG19_base.outputs = [VGG19_base.get_layer('block5_conv2').output]\n    input_layer = Input(shape=input_shape)\n    features = VGG19_base(input_layer)\n    model = Model(inputs=[input_layer], outputs=[features])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:11:08.371899Z","iopub.execute_input":"2021-10-14T12:11:08.372418Z","iopub.status.idle":"2021-10-14T12:11:08.380576Z","shell.execute_reply.started":"2021-10-14T12:11:08.372376Z","shell.execute_reply":"2021-10-14T12:11:08.378954Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"fe_model = build_VGG19()\nfe_model.trainable = False\nfe_model.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:11:10.224155Z","iopub.execute_input":"2021-10-14T12:11:10.224632Z","iopub.status.idle":"2021-10-14T12:11:10.286940Z","shell.execute_reply.started":"2021-10-14T12:11:10.224593Z","shell.execute_reply":"2021-10-14T12:11:10.285173Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def build_adversarial_model(generator, discriminator, feature_extractor):\n    \n    # input layer for high-resolution images\n    input_high_resolution = Input(shape=high_resolution_shape)\n\n    # input layer for low-resolution images\n    input_low_resolution = Input(shape=low_resolution_shape)\n\n    # generate high-resolution images from low-resolution images\n    generated_high_resolution_images = generator(input_low_resolution)\n\n    # extract feature maps from generated images\n    features = feature_extractor(generated_high_resolution_images)\n    \n    # make a discriminator non-trainable \n    discriminator.trainable = False\n    discriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n\n    # discriminator will give us a probability estimation for the generated high-resolution images\n    probs = discriminator(generated_high_resolution_images)\n\n    # create and compile \n    adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n    adversarial_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n    \n    return adversarial_model\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:11:13.311930Z","iopub.execute_input":"2021-10-14T12:11:13.312519Z","iopub.status.idle":"2021-10-14T12:11:13.322863Z","shell.execute_reply.started":"2021-10-14T12:11:13.312475Z","shell.execute_reply":"2021-10-14T12:11:13.321956Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"adversarial_model = build_adversarial_model(generator, discriminator, fe_model)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:11:13.632064Z","iopub.execute_input":"2021-10-14T12:11:13.632608Z","iopub.status.idle":"2021-10-14T12:11:13.662837Z","shell.execute_reply.started":"2021-10-14T12:11:13.632574Z","shell.execute_reply":"2021-10-14T12:11:13.661308Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# initialize \n\nlosses = {\"d_history\":[], \"g_history\":[]}\npsnr = {'psnr_quality': []}\nssim = {'ssim_quality': []}","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:11:14.015832Z","iopub.execute_input":"2021-10-14T12:11:14.016371Z","iopub.status.idle":"2021-10-14T12:11:14.022775Z","shell.execute_reply.started":"2021-10-14T12:11:14.016334Z","shell.execute_reply":"2021-10-14T12:11:14.021696Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# training loop\n\nfor epoch in range(epochs):\n\n    d_history = []\n    g_history = []\n    \n    image_list = get_train_images(data_path)\n    \n    \"\"\"\n    Train the discriminator network\n    \"\"\"\n    \n    hr_images, lr_images = sample_images(image_list, \n                                         batch_size=batch_size,\n                                         low_resolution_shape=low_resolution_shape,\n                                         high_resolution_shape=high_resolution_shape)\n    \n    \n    # normalize the images\n    hr_images = hr_images / 127.5 - 1.\n    lr_images = lr_images / 127.5 - 1.\n    \n    # generate high-resolution images from low-resolution images\n    generated_high_resolution_images = generator.predict(lr_images)\n    \n    # generate a batch of true and fake labels \n    real_labels = np.ones((batch_size, 16, 16, 1))\n    fake_labels = np.zeros((batch_size, 16, 16, 1))\n    \n \n    d_loss_real = discriminator.train_on_batch(hr_images, real_labels)\n    d_loss_real =  np.mean(d_loss_real)\n    d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n    d_loss_fake =  np.mean(d_loss_fake)\n    \n    # calculate total loss of discriminator as average loss on true and fake labels\n    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n    losses['d_history'].append(d_loss)\n   \n\n    \"\"\"\n        Train the generator network\n    \"\"\"\n      \n    # sample a batch of images    \n    hr_images, lr_images = sample_images(image_list, \n                                         batch_size=batch_size,\n                                         low_resolution_shape=low_resolution_shape,\n                                         high_resolution_shape=high_resolution_shape)\n    \n    \n    # normalize the images\n    hr_images = hr_images / 127.5 - 1.\n    lr_images = lr_images / 127.5 - 1.\n    \n    \n    \n    # extract feature maps for true high-resolution images\n    image_features = fe_model.predict(hr_images)\n\n\n    \n    # train the generator\n    g_loss = adversarial_model.train_on_batch([lr_images, hr_images],\n                                               [real_labels, image_features])\n    \n    losses['g_history'].append(0.5 * (g_loss[1]))\n    \n    \n    \n    # calculate the psnr  \n    ps = compute_psnr(hr_images, generated_high_resolution_images) \n    psnr['psnr_quality'].append(ps)\n            \n    # calculate the ssim \n    ss = compute_ssim(hr_images, generated_high_resolution_images)   \n    ssim['ssim_quality'].append(ss)\n\n    \n  \n    \"\"\"\n        save and print image samples\n    \"\"\"\n    \n    if epoch % 500 == 0:\n        \n        hr_images, lr_images = sample_images(image_list, \n                                             batch_size=batch_size,\n                                             low_resolution_shape=low_resolution_shape,\n                                             high_resolution_shape=high_resolution_shape)\n    \n    \n        # normalize the images\n        hr_images = hr_images / 127.5 - 1.\n        lr_images = lr_images / 127.5 - 1.\n    \n    \n        generated_images = generator.predict_on_batch(lr_images)\n    \n        for index, img in enumerate(generated_images):\n            if index < 3:   # comment this line to display all the images\n                save_images(hr_images[index], lr_images[index], img,\n                            path=\"/kaggle/working/img_{}_{}\".format(epoch, index))  ","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:11:16.770059Z","iopub.execute_input":"2021-10-14T12:11:16.770463Z","iopub.status.idle":"2021-10-14T12:11:40.121954Z","shell.execute_reply.started":"2021-10-14T12:11:16.770430Z","shell.execute_reply":"2021-10-14T12:11:40.120040Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# plots - post training\n\nplot_loss(losses)\nplot_psnr(psnr)\nplot_ssim(ssim)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:12:28.191179Z","iopub.execute_input":"2021-10-14T12:12:28.191691Z","iopub.status.idle":"2021-10-14T12:12:28.759895Z","shell.execute_reply.started":"2021-10-14T12:12:28.191645Z","shell.execute_reply":"2021-10-14T12:12:28.759013Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# save model weights\n\ngenerator.save_weights(\"/kaggle/working/srgan_generator.h5\")\ndiscriminator.save_weights(\"/kaggle/working/srgan_discriminator.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:12:28.761707Z","iopub.execute_input":"2021-10-14T12:12:28.762310Z","iopub.status.idle":"2021-10-14T12:12:29.025985Z","shell.execute_reply.started":"2021-10-14T12:12:28.762262Z","shell.execute_reply":"2021-10-14T12:12:29.024989Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}